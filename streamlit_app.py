# app.py â€” íŒŸìºìŠ¤íŠ¸ AI ì½”ì¹˜ (í™”ì ìˆ˜ í•„ìˆ˜ ì…ë ¥ + í™”ìë¶„ë¦¬/ì§„ë‹¨/í†µê³„/íƒ€ì„ë¼ì¸/Gemini í†µí•©)

import streamlit as st
import pandas as pd
import numpy as np
import tempfile, os, json, time as _time
from datetime import datetime

import plotly.express as px
from plotly import graph_objects as go

from faster_whisper import WhisperModel
import google.generativeai as genai

# --- NumPy 2.0 ì„ì‹œ í˜¸í™˜ (ì¼ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ np.NaN ì°¸ì¡° ëŒ€ë¹„) ---
if not hasattr(np, "NaN"):
    np.NaN = np.nan

# HF login for diarization
try:
    from huggingface_hub import login as hf_login
except Exception:
    hf_login = None  # ë¯¸ì„¤ì¹˜ ì‹œ ë¬´ì‹œ

# ==================== Config & Secrets ====================
GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY")
HF_TOKEN = st.secrets.get("HF_TOKEN")   # ì—†ìœ¼ë©´ í™”ìë¶„ë¦¬ ë¹„í™œì„±

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

if HF_TOKEN and hf_login is not None:
    try:
        hf_login(HF_TOKEN)
    except Exception:
        pass  # ë¡œê·¸ì¸ ì‹¤íŒ¨í•´ë„ ì•±ì€ ê³„ì† ë™ì‘

st.set_page_config(page_title="íŒŸìºìŠ¤íŠ¸ AI ì½”ì¹˜", layout="wide")
st.title("ğŸ§ íŒŸìºìŠ¤íŠ¸ AI ì½”ì¹˜ & ìê¸° ì„±ì°°")

st.markdown("""
1) ì˜¤ë””ì˜¤(WAV/MP3/M4A) ì—…ë¡œë“œ â†’ 2) ì£¼ì œ ì…ë ¥ â†’ 3) **AI ë¶„ì„ ì‹œì‘í•˜ê¸°**  
Hugging Face í† í°ì´ ìˆìœ¼ë©´ **í™”ì ë¶„ë¦¬**ê°€ ì ìš©ë˜ì–´ ê°œì¸ë³„ ì°¸ì—¬ë„(ë°œí™” íšŸìˆ˜/ì‹œê°„/ë¹„ìœ¨)ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
""")

# ==================== Utils ====================
def _sec_to_mmss(s: float) -> str:
    if s is None or s < 0:
        return "00:00"
    return _time.strftime("%M:%S", _time.gmtime(float(s)))

# ==================== Models (cache) ====================
@st.cache_resource
def load_whisper():
    return WhisperModel("small", device="cpu", compute_type="int8")
model_whisper = load_whisper()

@st.cache_resource
def load_diar_pipeline():
    """pyannote diarization pipeline (í† í° ì—†ìœ¼ë©´ None ë°˜í™˜)"""
    if not HF_TOKEN:
        return None
    try:
        from pyannote.audio import Pipeline
        pipe = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", use_auth_token=HF_TOKEN)
        return pipe
    except Exception as e:
        st.warning(f"í™”ì ë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
diar_pipeline = load_diar_pipeline()

# ==================== Core: STT + ê¸°ë³¸ ì§€í‘œ ====================
def analyze_podcast_audio(file_path, progress_callback=None):
    if progress_callback: progress_callback(10, "STT ë³€í™˜ ì¤‘... (ê¸¸ì´ì— ë”°ë¼ ìˆ˜ì‹­ ì´ˆ ì†Œìš”)")
    segments, info = model_whisper.transcribe(file_path, vad_filter=True, word_timestamps=False)

    if progress_callback: progress_callback(55, "í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ê¸°ë³¸ ì§€í‘œ ê³„ì‚°...")

    rows = [{"start": round(s.start, 2), "end": round(s.end, 2), "text": s.text.strip()} for s in segments]
    df = pd.DataFrame(rows)

    if df.empty:
        total_audio = round(getattr(info, "duration", 0) / 60, 1) if info else 0.0
        return pd.DataFrame(columns=["start","end","text","duration","word_count"]), {
            "ì´ ê¸¸ì´(ë¶„)": total_audio, "ë°œí™” ì´ ì‹œê°„(ë¶„)": 0.0, "ë§ì†ë„(WPM)": 0.0, "ì¹¨ë¬µ ë¹„ìœ¨(%)": 100.0
        }

    df["duration"] = df["end"] - df["start"]
    df["word_count"] = df["text"].str.split().str.len()

    total_time = float(df["duration"].sum())
    total_audio = float(getattr(info, "duration", total_time))
    wpm = (df["word_count"].sum() / (total_time / 60)) if total_time > 0 else 0
    silence_ratio = max(0, 1 - (total_time / total_audio)) if total_audio > 0 else 0

    metrics = {
        "ì´ ê¸¸ì´(ë¶„)": round(total_audio / 60, 1),
        "ë°œí™” ì´ ì‹œê°„(ë¶„)": round(total_time / 60, 1),
        "ë§ì†ë„(WPM)": round(wpm, 1),
        "ì¹¨ë¬µ ë¹„ìœ¨(%)": round(silence_ratio * 100, 1),
    }
    return df, metrics

# ==================== Diarization + attach speakers ====================
def diarize_audio(file_path, progress_callback=None, num_speakers: int | None = None):
    if diar_pipeline is None:
        return pd.DataFrame(columns=["start","end","speaker"])
    if progress_callback: progress_callback(65, "í™”ì ë¶„ë¦¬ ì¤‘...")

    diar_kwargs = {}
    if num_speakers and num_speakers > 0:
        diar_kwargs["num_speakers"] = int(num_speakers)

    diar = diar_pipeline(file_path, **diar_kwargs)

    out = []
    for turn, _, spk in diar.itertracks(yield_label=True):
        out.append({"start": round(turn.start, 2), "end": round(turn.end, 2), "speaker": spk})
    return pd.DataFrame(out)

def attach_speaker(trans_df: pd.DataFrame, diar_df: pd.DataFrame):
    """ê° Whisper ë°œí™”ì— ê°€ì¥ ë§ì´ ê²¹ì¹˜ëŠ” í™”ì ë¼ë²¨ ë¶€ì—¬"""
    if diar_df.empty or trans_df.empty:
        trans_df["speaker"] = "S1"
        return trans_df
    speakers = []
    for _, u in trans_df.iterrows():
        overlap = diar_df.apply(lambda r: max(0, min(u.end, r.end) - max(u.start, r.start)), axis=1)
        if overlap.max() <= 0:
            speakers.append("UNK")
        else:
            speakers.append(diar_df.loc[int(overlap.idxmax()), "speaker"])
    trans_df["speaker"] = speakers
    return trans_df

def per_speaker_stats(df: pd.DataFrame):
    """í™”ìë³„ ë°œí™”íšŸìˆ˜/ì‹œê°„/ë¹„ìœ¨ + 'ì´ NíšŒ ì¤‘ níšŒ = p%'"""
    total_turns = int(len(df))
    total_time = float(df["duration"].sum()) if total_turns else 0.0

    g = df.groupby("speaker", dropna=False).agg(
        turns=("text","count"),
        speak_time=("duration","sum")
    ).reset_index()

    g["í„´ ë¹„ìœ¨(%)"] = (g["turns"] / total_turns * 100) if total_turns > 0 else 0.0
    g["ì‹œê°„ ë¹„ìœ¨(%)"] = (g["speak_time"] / total_time * 100) if total_time > 0 else 0.0
    g["í„´ ë¹„ìœ¨(%)"] = g["í„´ ë¹„ìœ¨(%)"].round(1)
    g["ì‹œê°„ ë¹„ìœ¨(%)"] = g["ì‹œê°„ ë¹„ìœ¨(%)"].round(1)
    if total_turns > 0:
        g["ìš”ì•½"] = g.apply(lambda r: f"ì´ {total_turns}íšŒ ì¤‘ {int(r.turns)}íšŒ = {round(r['í„´ ë¹„ìœ¨(%)'],1)}%", axis=1)
    else:
        g["ìš”ì•½"] = "-"
    return g

# ==================== Gemini í‰ê°€ ====================
def gemini_podcast_analysis(df, topic_hint="", progress_callback=None):
    if df.empty:
        return {"structure":1,"delivery":1,"content":1,"creativity":1,"summary":"ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•„ AI í‰ê°€ë¥¼ ìƒëµí–ˆìŠµë‹ˆë‹¤."}
    if progress_callback: progress_callback(75, "AI ëª¨ë¸ì— ì½˜í…ì¸  í‰ê°€ ìš”ì²­ ì¤‘...")

    records = df["text"].tolist()
    prompt = f"""
ë„ˆëŠ” í•™ìƒë“¤ì˜ ë°œí‘œ ëŠ¥ë ¥ì„ ë•ëŠ” íŒŸìºìŠ¤íŠ¸ ì½”ì¹­ AIì•¼. ì „ì‚¬ë³¸ì„ ë¶„ì„í•´ ì•„ë˜ ê¸°ì¤€ìœ¼ë¡œ JSONë§Œ ì¶œë ¥í•´.
ì£¼ì œ: {topic_hint}
[êµ¬ì„± 1~5] ë…¼ë¦¬/ì „í™˜, [ì „ë‹¬ë ¥ 1~5] ë°œìŒÂ·ì†ë„Â·ì–µì–‘, [ë‚´ìš© 1~5] ì •í™•ì„±Â·ê·¼ê±°Â·í•µì‹¬ì„±, [ì°½ì˜ì„± 1~5] ë…ì°½ì„±Â·ì‚¬ë¡€/ì—°ì¶œ.
ì¶œë ¥ ONLY JSON: {{"structure":int,"delivery":int,"content":int,"creativity":int,"summary":"2~3ë¬¸ì¥ ì½”ë©˜íŠ¸"}}
ì „ì‚¬: {records}
""".strip()

    for m in ["gemini-2.5-flash", "gemini-pro"]:
        try:
            mdl = genai.GenerativeModel(m)
            res = mdl.generate_content(prompt)
            txt = (res.text or "").strip()
            if txt.startswith("```"):
                txt = txt.strip("` \n")
                if txt.lower().startswith("json"):
                    txt = txt[4:].strip()
            if "{" in txt and "}" in txt:
                txt = txt[txt.find("{"): txt.rfind("}")+1]
            out = json.loads(txt)
            for k in ["structure","delivery","content","creativity","summary"]:
                out.setdefault(k, 1 if k!="summary" else "")
            if progress_callback: progress_callback(95, "AI í‰ê°€ ì™„ë£Œ. ê²°ê³¼ ì •ë¦¬ ì¤‘...")
            return out
        except Exception:
            continue
    st.error("âš ï¸ AI ì‘ë‹µì„ í•´ì„í•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
    return {"structure":1,"delivery":1,"content":1,"creativity":1,"summary":""}

# ==================== UI: ì—…ë¡œë“œ/ì„¤ì •/ì‹¤í–‰ (í¼ + í•„ìˆ˜ ì…ë ¥ ê°•ì œ) ====================
uploaded_file = st.file_uploader("ğŸµ íŒŸìºìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ (WAV/MP3/M4A)", type=["wav","mp3","m4a"])
topic_hint = st.text_input("ğŸ“Œ íŒŸìºìŠ¤íŠ¸ ì£¼ì œ (í•„ìˆ˜)", value="")

# í™”ì ë¶„ë¦¬ íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
diar_available = diar_pipeline is not None

# í¼: í•„ìˆ˜ê°’ ì—†ìœ¼ë©´ ë¶„ì„ ì‹œì‘ ì•ˆ í•¨
with st.form("analyze_form", clear_on_submit=False):
    if diar_available:
        st.markdown("### ğŸ‘¥ í™”ì ë¶„ë¦¬ ì„¤ì •")
        use_diar = st.checkbox("í™”ì ë¶„ë¦¬ ì‚¬ìš©(ê¶Œì¥)", value=True)
        num_speakers = st.number_input(
            "í™”ì ìˆ˜(í•„ìˆ˜)", min_value=1, max_value=6, step=1, value=2,
            help="ëŒ€ë¶€ë¶„ 2~3ëª…ìœ¼ë¡œ ì‹œì‘í•´ ë³´ì„¸ìš”."
        ) if use_diar else None
    else:
        use_diar = False
        num_speakers = None
        st.info("â„¹ï¸ Hugging Face í† í°ì´ ì—†ì–´ í™”ì ë¶„ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤. (ë‹¨ì¼ í™”ì ì²˜ë¦¬)")

    submit = st.form_submit_button("ğŸ¤– AI ë¶„ì„ ì‹œì‘í•˜ê¸°")

    if submit:
        # 1) ê³µí†µ ì…ë ¥ í™•ì¸
        if not uploaded_file:
            st.error("ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”."); st.stop()
        if not topic_hint.strip():
            st.error("íŒŸìºìŠ¤íŠ¸ ì£¼ì œë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."); st.stop()
        # 2) í™”ì ë¶„ë¦¬ í•„ìˆ˜ê°’ í™•ì¸
        if diar_available and use_diar and (num_speakers is None):
            st.error("í™”ì ìˆ˜ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."); st.stop()

        # ---- ì‹¤ì œ ë¶„ì„ ì‹œì‘ ----
        progress = st.progress(0); status = st.empty()
        def step(p,msg): progress.progress(int(p)); status.info(msg)

        step(5, "ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„ ì¤‘...")
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp:
            tmp.write(uploaded_file.getvalue()); tmp_path = tmp.name

        # 1) STT + ê¸°ë³¸ì§€í‘œ
        df, basic = analyze_podcast_audio(tmp_path, step)

        # 2) í™”ì ë¶„ë¦¬ â†’ speaker ë¼ë²¨ ë¶€ì°©
        if diar_available and use_diar:
            diar_df = diarize_audio(tmp_path, step, num_speakers=int(num_speakers))
        else:
            diar_df = pd.DataFrame(columns=["start","end","speaker"])
        st.session_state.diar_df = diar_df
        df = attach_speaker(df, diar_df)

        # 3) Gemini í‰ê°€
        gem = gemini_podcast_analysis(df, topic_hint, step)

        try: os.remove(tmp_path)
        except: pass

        st.session_state.analysis_complete = True
        st.session_state.df = df
        st.session_state.metrics_basic = basic
        st.session_state.metrics_gemini = gem
        st.session_state.spk_stats = per_speaker_stats(df)

        step(100, "ë¶„ì„ ì™„ë£Œ! ì•„ë˜ì—ì„œ ë¦¬í¬íŠ¸ë¥¼ í™•ì¸í•˜ì„¸ìš”."); status.success("ë¶„ì„ ì™„ë£Œ!")

# ==================== ê²°ê³¼ íƒ­ & ì§„ë‹¨ ====================
if st.session_state.get("analysis_complete"):
    st.divider()
    st.header("ğŸ“ˆ AI ì½”ì¹˜ì˜ ë¶„ì„ ë¦¬í¬íŠ¸")

    # ğŸ” í™”ì ë¶„ë¦¬ ì§„ë‹¨
    if 'diar_df' in st.session_state:
        dd = st.session_state.diar_df
        if dd.empty:
            st.info("â„¹ï¸ í™”ì ë¶„ë¦¬ ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. (í† í° ë¯¸ì„¤ì •/ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨/1ì¸ í™”ì ê°€ëŠ¥)")
        else:
            st.success(f"âœ… í™”ì ë¶„ë¦¬ ì™„ë£Œ: ì„¸ê·¸ë¨¼íŠ¸ {len(dd)}ê°œ, í™”ì {dd['speaker'].nunique()}ëª…")
            with st.expander("í™”ì ë¶„ë¦¬ ì›ì‹œ ì„¸ê·¸ë¨¼íŠ¸ ë³´ê¸°"):
                st.dataframe(dd.head(50), use_container_width=True)

    tab1, tab2, tab3 = st.tabs(["ğŸ“Š ì¢…í•©/í™”ìë³„", "ğŸ—£ï¸ ë°œí™” íƒ€ì„ë¼ì¸", "ğŸ¤” ìê¸° ì„±ì°°"])

    # --- íƒ­1: ì¢…í•© & í™”ìë³„ ---
    with tab1:
        st.subheader("ğŸ¯ ì½˜í…ì¸  í‰ê°€ (Gemini)")
        st.info(f"**AI ì´í‰:** {st.session_state.metrics_gemini['summary']}")
        score_df = pd.DataFrame({
            "í•­ëª©": ["êµ¬ì„±","ì „ë‹¬ë ¥","ë‚´ìš© ì¶©ì‹¤ë„","ì°½ì˜ì„±"],
            "AI ì ìˆ˜": [
                st.session_state.metrics_gemini["structure"],
                st.session_state.metrics_gemini["delivery"],
                st.session_state.metrics_gemini["content"],
                st.session_state.metrics_gemini["creativity"],
            ],
        })
        fig_bar = px.bar(score_df, x="í•­ëª©", y="AI ì ìˆ˜", range_y=[0,5.5], text="AI ì ìˆ˜", color="í•­ëª©")
        fig_bar.update_traces(textposition="outside"); st.plotly_chart(fig_bar, use_container_width=True)

        st.subheader("â±ï¸ ì œì‘ í’ˆì§ˆ ì§€í‘œ")
        cols = st.columns(len(st.session_state.metrics_basic))
        for col, (label, value) in zip(cols, st.session_state.metrics_basic.items()):
            col.metric(label, value)

        # ğŸ”¥ í™”ìë³„ ì°¸ì—¬ë„
        st.subheader("ğŸ‘¥ í™”ìë³„ ì°¸ì—¬ë„")
        spk = st.session_state.spk_stats.copy()
        if not spk.empty:
            spk_disp = spk.rename(columns={"speaker":"í™”ì","turns":"ë°œí™” íšŸìˆ˜","speak_time":"ë°œí™” ì‹œê°„(ì´ˆ)"})
            st.dataframe(spk_disp[["í™”ì","ë°œí™” íšŸìˆ˜","í„´ ë¹„ìœ¨(%)","ë°œí™” ì‹œê°„(ì´ˆ)","ì‹œê°„ ë¹„ìœ¨(%)","ìš”ì•½"]],
                         use_container_width=True)
            st.plotly_chart(px.bar(spk, x="speaker", y="turns", text="í„´ ë¹„ìœ¨(%)",
                                   title="í™”ìë³„ ë°œí™” íšŸìˆ˜(ì´ NíšŒ ëŒ€ë¹„)"), use_container_width=True)
        else:
            st.caption("í™”ì ë¶„ë¦¬ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. (HF í† í° ë¯¸ì„¤ì •/ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨/1ì¸ í™”ì)")

    # --- íƒ­2: íƒ€ì„ë¼ì¸ (go.Bar + base, í™”ìë³„ ìƒ‰ìƒ) ---
    with tab2:
        st.subheader("ğŸ•’ ë°œí™” êµ¬ê°„ íƒ€ì„ë¼ì¸")
        df2 = st.session_state.df.copy()
        if df2.empty:
            st.warning("ì˜¤ë””ì˜¤ì—ì„œ ìŒì„±ì´ ê°ì§€ë˜ì§€ ì•Šì•„ íƒ€ì„ë¼ì¸ì„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            df2 = df2.reset_index(drop=True)
            df2["utt_id"] = df2.index.map(lambda i: f"#{i+1}")
            df2["bar_len"] = (df2["end"] - df2["start"]).clip(lower=0.01)

            uniq = df2["speaker"].fillna("S1").unique().tolist()
            pal = px.colors.qualitative.Set2
            color_map = {s: pal[i % len(pal)] for i, s in enumerate(uniq)}
            colors = df2["speaker"].fillna("S1").map(color_map)

            total_audio = max(float(df2["end"].max()), 0.0)
            tick_vals = np.linspace(0.0, total_audio, 7)
            tick_text = [_sec_to_mmss(v) for v in tick_vals]

            fig = go.Figure()
            fig.add_trace(go.Bar(
                x=df2["bar_len"], y=df2["utt_id"], base=df2["start"], orientation="h",
                marker=dict(color=colors),
                hovertext=df2.apply(lambda r: f"[{r['speaker']}] {r['text']}", axis=1),
                hovertemplate="<b>%{y}</b><br>ì‹œì‘: %{base:.2f}s<br>ê¸¸ì´: %{x:.2f}s<br><br>%{hovertext}"
            ))
            fig.update_layout(
                title="ë°œí™” êµ¬ê°„ (í™”ìë³„ ìƒ‰ìƒ)",
                barmode="stack", bargap=0.15,
                xaxis=dict(title="ì˜¤ë””ì˜¤ ì‹œê°„ (ë¶„:ì´ˆ)", tickmode="array", tickvals=tick_vals, ticktext=tick_text, rangemode="nonnegative"),
                yaxis=dict(title="ë°œí™” ID"),
                height=440, showlegend=False
            )
            st.plotly_chart(fig, use_container_width=True)

    # --- íƒ­3: ìê¸° ì„±ì°° (ì €ì¥ ì—†ìŒ) ---
    with tab3:
        st.subheader("ğŸ¤” ìŠ¤ìŠ¤ë¡œ ì ê²€í•˜ê¸°")
        st.slider("1. êµ¬ì„±", 1, 5, 3)
        st.slider("2. ì „ë‹¬ë ¥", 1, 5, 3)
        st.slider("3. ë‚´ìš© ì¶©ì‹¤ë„", 1, 5, 3)
        st.slider("4. ì°½ì˜ì„±", 1, 5, 3)
        st.text_area("ë©”ëª¨ (ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤)")
